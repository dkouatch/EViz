{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading OMI Satellite Data Using h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primary Resources:\n",
    "\n",
    "https://docs.h5py.org/en/stable/quick.html\n",
    "\n",
    "https://docserver.gesdisc.eosdis.nasa.gov/repository/Mission/OMI/3.3_ScienceDataProductDocumentation/3.3.2_ProductRequirements_Designs/OMNO2d_FileSpec_V003.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import hvplot.xarray\n",
    "from cartopy import crs as ccrs\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import pprint\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggles off alphabetical sorting\n",
    "pprint.sorted = lambda x, key=None:x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample OMI Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/deonkouatchou/eviz/eviz_datasource_dev/Samples/OMI/\"\n",
    "file_name = \"OMI-Aura_L3-OMTO3e_2022m0709_v003-2022m0711t031807.he5\"\n",
    "file = file_path + file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About HDF5 Files\n",
    "\n",
    "An `HDF5` file is a container for two types of objects: **datasets** and **groups**.\n",
    "\n",
    "**Datasets** are array-like collections of data, while **groups** are folder-like containers that hold datasets and/or other groups/sub-groups. \n",
    "\n",
    "In terms of their function, groups work like dictionaries and datasets work like NumPy arrays.\n",
    "\n",
    "While `HDF5` objects may have the characteristic of having interfaces modeled after well-known Python data types, in order to have the same string representation, they often must be type casted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening file for reading\n",
    "fid = h5py.File(file, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Hierarchy\n",
    "\n",
    "File -->  Group -->  Sub-group -->  Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `visit()` function returns the hierarchy of the file by utilizing the Python `print()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.visit(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even incorporate `lambda` or use predefined functions to retrieve more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.visit(lambda x: print(x, fid[x], \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve hierarchy and corresponding objects\n",
    "def print_more(name):\n",
    "    print(name, fid[name], \"\\n\")\n",
    "    \n",
    "fid.visit(print_more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the type of each object, for groups, the number of members and its path is returned. For datasets, the name, shape, and array type is returned instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Groups / Subgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using what we know about the behavior of groups, we can access all objects like dictionaries.\n",
    "\n",
    "We can access group and subgroup keys,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_keys = list(fid.keys())\n",
    "print(fid_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group and subgroup values,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_values = list(fid.values())\n",
    "print(fid_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group and subgroup items,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_items = dict(fid.items())\n",
    "print(fid_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or we can access the objects within them themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fid['HDFEOS']['ADDITIONAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict(fid['HDFEOS']['ADDITIONAL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Information\n",
    "\n",
    "Let's use a the `/HDFEOS/GRIDS/` sub-group as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group = fid['HDFEOS']['GRIDS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access group names (includes path),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the parent group of a subgroup, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the file to which the group belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group.file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we can access the **attributes** through the `attrs` variable which follows a dictionary-like interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group_attrs = dict(sample_group.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this group doesn't have any attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Application\n",
    "\n",
    "At first glance, it appears that most of the groups and sub-groups in the folder are irrelevant. When looking at the hierarchy, they either lead to the data itself or to other empty sub-groups and datasets.\n",
    "\n",
    "In reality, they may hold crucial information stored as attributes. Luckily, we can take advantage of the `visit()` function to get our \"invisible\" metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_attrs(name):\n",
    "    print(name, \"\\n\\tAttributes:\", fid[name].attrs.keys(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using a pre-defined function, we can access the attribute keys of every single object in the `HDF5` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.visit(print_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to **file-level attributes** and even **coordinate metadata**, we can access our **dataset attributes** as they, too, use the `attrs` variable to access them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Top-level Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File-level Attributes\n",
    "\n",
    "From displaying all attributes above, we can see that file-level attributes are stored as attributes w/in the `HDFEOS/ADDITIONAL/FILE_ATTRIBUTES/` sub-group.\n",
    "\n",
    "Since attributes have a dictionary-like interface in `h5py`, it's simple to obtain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_attrs = dict( fid['HDFEOS']['ADDITIONAL']['FILE_ATTRIBUTES'].attrs )\n",
    "\n",
    "file_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`h5py` stores the attribute values as `NumPy` data types: `numpy.ndarray` for all numeric and array representations and `numpy.bytes_` for all string and character representations along with tuples and dictionaries.\n",
    "\n",
    "While we could leave them that way, it would definitely be more convenient to convert them into more familiar data types due to their string representations. Thankfully, the `isinstance()` function exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in file_attrs.items():\n",
    "    if isinstance(item, np.ndarray):   # Converts np arrays to a list to, if applicable, an int or float\n",
    "        item = list(item)\n",
    "        \n",
    "        if len(item) == 1:\n",
    "            item = item[0]\n",
    "    elif isinstance(item, np.bytes_):   # Converts np bytes to an np string to a Python string\n",
    "        item = str(item.astype('str'))\n",
    "        \n",
    "        if item[0] == '(' or item[0] == '{':   # Converts to tuple or dict if applicable\n",
    "            item = eval(item)\n",
    "        # **eval() relaiability??**\n",
    "            \n",
    "    file_attrs[key] = item   # Updates any changes to the key value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(file_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coordinates and Plotting Information\n",
    "\n",
    "Our plotting-related metadata seems to be stored as attributes in the `HDFEOS/GRIDS/OMI Column Amount O3` sub-group. We can try to access them the same way as file attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attrs = dict( fid['HDFEOS']['GRIDS']['OMI Column Amount O3'].attrs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same data type conversion method, we can get more convenient data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in plot_attrs.items():\n",
    "    if isinstance(item, np.ndarray):   # Converts np arrays to a list to, if applicable, an int or float\n",
    "        item = list(item)\n",
    "        \n",
    "        if len(item) == 1:\n",
    "            item = item[0]\n",
    "    elif isinstance(item, np.bytes_):   # Converts np bytes to an np string to a Python string\n",
    "        item = str(item.astype('str'))\n",
    "        \n",
    "        if item[0] == '(' or item[0] == '{':   # Converts to tuple or dict if applicable\n",
    "            item = eval(item)\n",
    "        # **eval() relaiability??**\n",
    "            \n",
    "    plot_attrs[key] = item   # Updates any changes to the key value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These attributes give us all the information we need to construct coordinates need for `XArray` datasets.\n",
    "\n",
    "First, we want to identify our coordinate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonW = plot_attrs['GridSpan'][0]\n",
    "lonE = plot_attrs['GridSpan'][1]\n",
    "latS = plot_attrs['GridSpan'][2]\n",
    "latN = plot_attrs['GridSpan'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we just need to obtain the number of lats and lons in the grid (our dimension sizes), which is also readily available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_size = plot_attrs['NumberOfLongitudesInGrid']\n",
    "lat_size = plot_attrs['NumberOfLatitudesInGrid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, using NumPy's `linspace()` function, we can now create our coordinates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = np.linspace(lonW, lonE, lon_size)\n",
    "lats = np.linspace(latS, latN, lat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Longitudes:\\n', lons)\n",
    "print('Latitudes:\\n', lats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Data Fields and Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking back at the file layout, we can see that the data appears to be w/in the subgroup `/HDFEOS/GRIDS/OMI Column Amount O3/Data Fields/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group = fid['HDFEOS']['GRIDS']['OMI Column Amount O3']['Data Fields']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take advantage of the `visit()` function once again and get some descriptive information and attributes of each dataset w/in the sub-group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_info(name):\n",
    "    print('Name:', name, \n",
    "          '\\n\\tInfo:', data_group[name],\n",
    "          '\\n\\tAttrs:', data_group[name].attrs.keys(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group.visit(print_data_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets\n",
    "\n",
    "Given our previous knowledge of reading attributes, accessing important keys such as missing and fill values, scale factors, and offset values will be straightforward.\n",
    "\n",
    "Let's use the `SolarZenithAngle` dataset as our sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds = data_group['SolarZenithAngle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now examine the attributes more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_attrs = dict(sample_ds.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for our signature data type conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in sample_ds_attrs.items():\n",
    "    if isinstance(item, np.ndarray):   # Converts np arrays to a list to, if applicable, an int or float\n",
    "        item = list(item)\n",
    "        \n",
    "        if len(item) == 1:\n",
    "            item = item[0]\n",
    "    elif isinstance(item, np.bytes_):   # Converts np bytes to an np string to a Python string\n",
    "        item = str(item.astype('str'))\n",
    "        \n",
    "        if item[0] == '(' or item[0] == '{':   # Converts to tuple or dict if applicable\n",
    "            item = eval(item)\n",
    "        # **eval() relaiability??**\n",
    "            \n",
    "    sample_ds_attrs[key] = item   # Updates any changes to the key value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can extract our targeted attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default values (also a reset if testing different datasets/variables)\n",
    "fill = None\n",
    "scale = 1\n",
    "offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sample_ds_attrs.items():\n",
    "    if key == '_FillValue':\n",
    "        fill = value  \n",
    "    if key == 'ScaleFactor':\n",
    "        scale = value\n",
    "    if key == 'Offset':\n",
    "        offset = value\n",
    "# data = data * scale + offset\n",
    "    \n",
    "print('Fill Value:', fill)\n",
    "print('Scale Factor:', scale)\n",
    "print('Offset:', offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we need ot do is to access our actual **data**. `h5py` makes this really simple. All we need to do is add `[()]` next to our dataset object and all of it is now in `NumPy` array format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = sample_ds[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing to access in our HDF5 file is dataset **dimensions**, known as **dimension scales** in `h5py`.\n",
    "\n",
    "We can access a dataset's dimensions by getting a list of dimension objects using the `dims()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_dims = list(sample_ds.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimension objects are simply another `HDF5` dataset. Normally, one would be able to access dimension labels and scales associated with each axis. For our OMI satellite data file, our dimension objects are empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_ds_dims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_dims[0].label   # would return dimension label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(sample_ds_dims[0].items())   # would return label and scales associated with this axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_ds_dims[0][0]   # would return scale data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we can try to match the dataset shape to our plotting attributes describing lon and lat size to assign our `xarray` dimension names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lon_size, lat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_ds.shape[0] == lon_size:\n",
    "    sample_ds_dims = ['lon', 'lat']\n",
    "elif sample_ds.shape[0] == lat_size:\n",
    "    sample_ds_dims = ['lat', 'lon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Configuring the order is important for our `xarray` DataArray initilizations.\n",
    "\n",
    "Now that we've gotten all the information we need, we can close our file reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion to XArray DataArrays and Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've been able to get all of the necessary information to create an `xarray` dataset, we can start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: NOT UP-TO-DATE WITH FUNCTIONS USED IN EVIZ/IVIZ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing our file identifier object\n",
    "'''\n",
    "    Parameter(s): file name string\n",
    "    Return Type(s): h5py file identifier object\n",
    "    Function: returns the file identifier object for reading a file in h5py\n",
    "'''\n",
    "def get_fid(filename):\n",
    "    fid = h5py.File(filename, 'r')\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing our datafield subgroup\n",
    "'''\n",
    "    Parameter(s): An h5pyfile file ID object\n",
    "    Return Type(s): An h5py group object\n",
    "    Function: returns the data field group (contents) of the file\n",
    "'''\n",
    "def get_data_group(fid):\n",
    "    parent_contents = dict(fid['HDFEOS']['GRIDS'])   # contents of our parent group\n",
    "    subparent = list(parent_contents.values())[0]   # our subparent group object\n",
    "    subparent_contents = dict(subparent)   # contents of our subparent group\n",
    "    data_group = list(subparent_contents.values())[0]   # our data group object\n",
    "    \n",
    "    return dict(data_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting our dtypes\n",
    "'''\n",
    "    Parameter(s): A dictionary (of attributes)\n",
    "    Return Type(s): A dictionary (of attributes)\n",
    "    Function: converts attribute dictionary from np data types to general Python data types\n",
    "'''\n",
    "def convert_dict_dtype(sample_dict):\n",
    "    for key, item in sample_dict.items():\n",
    "        if isinstance(item, np.ndarray):   # Converts np arrays to a list to, if applicable, an int or float\n",
    "            item = list(item)\n",
    "        \n",
    "            if len(item) == 1:\n",
    "                item = item[0]\n",
    "        elif isinstance(item, np.bytes_):   # Converts np bytes to an np string to a Python string\n",
    "            item = str(item.astype('str'))\n",
    "        \n",
    "            if item[0] == '(' or item[0] == '{':   # Converts to tuple or dict if applicable\n",
    "                item = eval(item)\n",
    "            # **eval() relaiability??**\n",
    "            \n",
    "        sample_dict[key] = item   # Updates any changes to the key value\n",
    "        \n",
    "    return sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing our file attributes\n",
    "'''\n",
    "    Parameter(s): A file identifier object\n",
    "    Return Type(s): A dictionary \n",
    "    Function: returns the file-level attributes in the proper data type \n",
    "'''\n",
    "def get_fid_attrs(fid):\n",
    "    fid_attrs = dict( fid['HDFEOS']['ADDITIONAL']['FILE_ATTRIBUTES'].attrs )\n",
    "    fid_attrs = convert_dict_dtype(fid_attrs)\n",
    "    \n",
    "    fid_attrs.update(get_plot_attrs(fid))\n",
    "    \n",
    "    return fid_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing plotting attributes\n",
    "'''\n",
    "    Parameter(s): An h5py file identifier object\n",
    "    Return Type(s): A dictionary\n",
    "    Function: returns the plotting attributes given the file ID object\n",
    "'''\n",
    "def get_plot_attrs(fid):\n",
    "    parent_contents = dict(fid['HDFEOS']['GRIDS'])\n",
    "    subgroup = list(parent_contents.values())[0]\n",
    "    \n",
    "    plot_attrs = dict(subgroup.attrs)\n",
    "    plot_attrs = convert_dict_dtype(plot_attrs)\n",
    "    \n",
    "    return plot_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing our dataset attributes\n",
    "'''\n",
    "    Parameter(s): A file identifier object\n",
    "    Return Type(s): A dictionary \n",
    "    Function: returns the file-level attributes (in proper data type)\n",
    "'''\n",
    "def get_ds_attrs(ds):\n",
    "    ds_attrs = dict(ds.attrs)\n",
    "    ds_attrs = convert_dict_dtype(ds_attrs)\n",
    "    \n",
    "    return ds_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing fill, scale, and offset values\n",
    "'''\n",
    "    Parameter(s): A dictionary of dataset attributes\n",
    "    Return Type(s): Either an integer, floating point, or 'None'\n",
    "    Function: returns the fill value of a given dataset object\n",
    "'''\n",
    "def get_fill(ds_attrs):\n",
    "    for key, value in ds_attrs.items():\n",
    "        if key == '_FillValue':\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "'''\n",
    "    Parameter(s): A dictionary of dataset attributes\n",
    "    Return Type(s): Either an integer, floating point, or 'None'\n",
    "    Function: returns the scale factor of a given dataset object\n",
    "'''\n",
    "def get_scale(ds_attrs):\n",
    "    for key, value in ds_attrs.items():\n",
    "        if key == 'ScaleFactor':\n",
    "            return value\n",
    "\n",
    "'''\n",
    "    Parameter(s): A dictionary of dataset attributes\n",
    "    Return Type(s): Either an integer, floating point, or 'None'\n",
    "    Function: returns the offset value of a given dataset object\n",
    "'''\n",
    "def get_offset(ds_attrs):\n",
    "    for key, value in ds_attrs.items():\n",
    "        if key == 'Offset':\n",
    "            return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing dataset data: ds[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restoring dataset data\n",
    "'''\n",
    "    Parameter(s): An h5py dataset object\n",
    "    Return Type(s): NumPy array\n",
    "    Function: restores the data of a given dataset object\n",
    "'''\n",
    "def restore_data(ds):\n",
    "    ds_attrs = get_ds_attrs(ds)\n",
    "    \n",
    "    fill = get_fill(ds_attrs)\n",
    "    scale = get_scale(ds_attrs)\n",
    "    offset = get_offset(ds_attrs)\n",
    "    \n",
    "    data = ds[()]#.astype('float')\n",
    "    \n",
    "    data = np.where(data != fill, data, np.nan)\n",
    "    data *= scale\n",
    "    data += offset\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing coordinates\n",
    "'''\n",
    "    Parameter(s): An h5py file identifier object\n",
    "    Return Type(s): A list of NumPy arrays\n",
    "    Function: returns the file coordinates given its identifier object\n",
    "'''\n",
    "def get_coords(fid):\n",
    "    plot_attrs = get_plot_attrs(fid)\n",
    "    \n",
    "    lonW = plot_attrs['GridSpan'][0]\n",
    "    lonE = plot_attrs['GridSpan'][1]\n",
    "    latS = plot_attrs['GridSpan'][2]\n",
    "    latN = plot_attrs['GridSpan'][3]\n",
    "    \n",
    "    lon_size = plot_attrs['NumberOfLongitudesInGrid']\n",
    "    lat_size = plot_attrs['NumberOfLatitudesInGrid']\n",
    "    \n",
    "    lons = np.linspace(lonW, lonE, lon_size)\n",
    "    lats = np.linspace(latS, latN, lat_size)\n",
    "    \n",
    "    return {'lons': lons, 'lats': lats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing dataset dimensions\n",
    "'''\n",
    "    Parameter(s): An h5py dataset and dictionary\n",
    "    Return Type(s): A dictionary\n",
    "    Function: gets dataset dimension names given dataset and coordinates\n",
    "'''\n",
    "def get_ds_dims(ds, coords):\n",
    "    dims = ds.dims\n",
    "    ds_dims = {}\n",
    "    \n",
    "    for i in range(len(dims)):\n",
    "        if dims[i].label == '':\n",
    "            if ds.shape[i] == coords['lons'].size:\n",
    "                ds_dims['lon'] = ds.shape[i]\n",
    "            elif ds.shape[i] == coords['lats'].size:\n",
    "                ds_dims['lat'] = ds.shape[i]\n",
    "        else:\n",
    "            ds_dims[dims[i].label] = ds.shape[i]\n",
    "    \n",
    "    return ds_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange coordinates order to match dimensions\n",
    "'''\n",
    "    Parameter(s): Two dictionaries\n",
    "    Return Type(s): A dictionary\n",
    "    Function: rearranges the coordinates order to match dimension shapes for a dataset\n",
    "'''\n",
    "def check_coords(dims, coords):\n",
    "    if list(dims.values())[0] != list(coords.values())[0].size:\n",
    "        temp = coords\n",
    "        coords = {list(coords.keys())[1]: list(coords.values())[1], \n",
    "                  list(coords.keys())[0]: list(coords.values())[0]}\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our xarray dataset\n",
    "'''\n",
    "    Parameter(s): A file name\n",
    "    Return Type(s): An xarray dataset\n",
    "    Function: converts OMI data in an HDF5 file to an xarray dataset\n",
    "'''\n",
    "def read_file(filename):\n",
    "    xr_ds = xr.Dataset()\n",
    "    \n",
    "    fid = get_fid(filename)\n",
    "    \n",
    "    data_group = get_data_group(fid)\n",
    "    fid_attrs = get_fid_attrs(fid)   \n",
    "    fid_coords = get_coords(fid)\n",
    "    \n",
    "    for name, hdf_ds in data_group.items():\n",
    "        data = restore_data(hdf_ds)       \n",
    "        ds_attrs = get_ds_attrs(hdf_ds)\n",
    "        \n",
    "        ds_dims = get_ds_dims(hdf_ds, fid_coords)\n",
    "        ds_coords = check_coords(ds_dims, fid_coords)\n",
    "    \n",
    "        xr_ds[name] = xr.DataArray(data, dims = list(ds_dims.keys()), coords = list(ds_coords.values()))\n",
    "        xr_ds[name].attrs = ds_attrs\n",
    "        \n",
    "        \n",
    "    xr_ds.attrs = fid_attrs    \n",
    "       \n",
    "    fid.close()    \n",
    "    return xr_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ds = read_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Our Data\n",
    "\n",
    "File size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_MB = file_ds.nbytes / 1000000\n",
    "\n",
    "file_MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = file_ds['RadiativeCloudFraction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic `matplotlib` plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic `hvPlot` plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More intermediate `hvPlot` plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.hvplot.quadmesh('lon', 'lat', projection = ccrs.PlateCarree(), geo = True, ylim = (-60, 80),\n",
    "                    project = True, cmap = 'blues', rasterize = True, coastline = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.hvplot.contour('lon', 'lat', projection = ccrs.PlateCarree(), ylim = (-60, 80),\n",
    "                   cmap = 'reds', coastline = True, geo = True, levels = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:viz_test]",
   "language": "python",
   "name": "conda-env-viz_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
